#ivar github: https://github.com/andersen-lab/ivar
#ivar manual: https://andersen-lab.github.io/ivar/html/manualpage.html#autotoc_md17

#titus variant calling with minimap: https://github.com/clmattson/dib_rotation/blob/master/doc/02_conda.md

#general SWIFT workflow info https://swiftbiosci.com/wp-content/uploads/2019/11/TEC-005-PRIMERCLIP-A-TOOL-FOR-TRIMMING-PRIMER-SEQUENCES-USING-COMMAND-LINE-OR-GALAXY-Rev-1.pdf

#processed data (batch 1): https://ucdavis.app.box.com/file/802677521499

```{bash}
#in crick:
 srun -J ivar -t 6:00:00 --mem=14gb -c 1 --pty bash
#make empty conda env
conda create -y -n ivar
conda install ivar

#Titus's workflow requires mamba
#in (base) conda:
conda install mamba

#from github:
git clone https://github.com/ucd-covid/minimap-workflow.git
cd minimap-workflow/
mamba env create --name covid -f environment.yml
conda activate covid

#get example data 
cmatt5@crick:~/SARS-COV2/minimap-workflow/data/PRJNA661613$ wget https://sra-pub-sars-cov2.s3.amazonaws.com/sra-src/SRR12596165/6_09_N1_S30_R1_001.fastq.gz.1
cmatt5@crick:~/SARS-COV2/minimap-workflow/data/PRJNA661613$ wget https://sra-pub-sars-cov2.s3.amazonaws.com/sra-src/SRR12596165/6_09_N1_S30_R2_001.fastq.gz.1

#get UCDavis environmental data
#in theoory you can copy straight from bioshare to crick but I downloaded to local and then scp'ed to crick. 
#put under /data 
```

**TO RUN TITUS' MINIMAP PIPELINE**
**Workflow details and variant calling parameters**

rule map_reads maps reads with minimap.
rule rmdup removes perfectly duplicated reads with samtools rmdup.
the rule call_variants_spec does highly specific variant calling with bcftools
QUAL<40 eliminates low quality mappings
DP<10 eliminates
GT!="1/1" eliminates heterozygous calls
the rule consensus_from_vcf builds a consensus using the VCF output by call_variants_spec, with bcftools consensus
the rule mask_low_coverage takes the consensus produced by consensus_from_vcf and masks bases that have mapping coverage strictly below 5

```{bash}
srun -J covid -t 6:00:00 --mem=25gb -c 1 --pty bash
conda activate covid

**#FIRST: need to get interleaved reads with 'abundtrime' name**
#do this by running ```Snakefile.merge-pe``` in the directory with the raw data (aka /data for now)
#This currently makes interleaved files with abundtrim.fq.gz in the name. Something like:
#snakemake -s /path/to/Snakefile.merge-pe -j 4
(covid) cmatt5@c2-3:~/SARS-COV2/minimap-workflow/data$ snakemake -s ~/SARS-COV2/minimap-workflow/Snakefile.merge-pe -j 4
#found 1 samples
#Building DAG of jobs...
#Using shell: /bin/bash
#Provided cores: 4
#Rules claiming more threads will be scaled down.
#Job counts:
#        count   jobs
#        1       all
#        1       merge_pe
#        2
#Select jobs to execute...

#[Wed Jun 16 11:59:52 2021]
#rule merge_pe:
#    input: GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R1_001.fastq.gz, GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R2_001.fastq.gz
#    output: GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.fq.gz
#    jobid: 1
#    wildcards: sample=GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14

#[Wed Jun 16 12:03:32 2021]
#Finished job 1.
#1 of 2 steps (50%) done
#Select jobs to execute...

#[Wed Jun 16 12:03:32 2021]
#localrule all:
#    input: GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.fq.gz
#    jobid: 0

#[Wed Jun 16 12:03:32 2021]
#Finished job 0.
#2 of 2 steps (100%) done
#Complete log: /home/cmatt5/SARS-COV2/minimap-workflow/data/.snakemake/log/2021-06-16T115951.950604.snakemake.log

#file called ```GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.fq.gz``` now in ./data

#now to run workflow:
#in minimap-workflow (i think?)
snakemake --use-conda -j 4 

#error:  File "/home/cmatt5/SARS-COV2/minimap-workflow/./variants_of_interest.py", line 3, in <module>
#    import screed
#ModuleNotFoundError: No module named 'screed'

 Probably have to conda install screed, whatever that is
 
#delete all output to start over
snakemake --delete-all-output --cores 1
#try again:
snakemake --use-conda -j 4 
#success!

```

OK. now i have some results, but the output .vcf file in unfiltered.


##### get OSU pipeline going #####

# workflow outline frpom Brett Tyler LAb: 

"## Trim reads w/ bbduk
bbduk.sh ktrim=r k=23 mink=11 hdist=1 qtrim=r1 trimq=15 minlength=30 maxns=0 {params.mem} t={threads} in1={input.R1} in2={input.R2} out1={output.R1} out2={output.R2} ref=/local/cluster/bbmap/resources/adapters.fa
## Run BWA mem
bwa mem -t {threads} -M -R '{params.rg}' {input.fa} {input.fq} > {output.sam}
## Coord sort sams
samtools sort -n {input.sam} -o {output.sam}
## Soft Clip
primerclip {input.master} {input.sam} {output.sam}
## Convert sam to bam
samtools view -b {input.sam} -o {output.bam}
## Sort reads
samtools sort {input.bam} -o {output.sort}
## Index reads
samtools index {input.bam}
## Get depth from Bam files
samtools depth -a {input.bam} | awk '$3 < 5' | cut -f 1,2 > {output.depth}
## call variants in g.vcf mode
gatk HaplotypeCaller --java-options {params.mem} -R {input.ref} -ERC GVCF -stand-call-conf 20 --dont-use-soft-clipped-bases -mbq 20 --max-reads-per-alignment-start 0 --linked-de-bruijn-graph --recover-all-dangling-branches --sample-ploidy {params.ploidy} --input {input.dedup} --output {output.gvcf}
## Combine gvcfs
gatk CombineGVCFs --java-options {params.mem} -R {input.ref} {lgvcfs} -O {output.gvcf}
## Genotype merged gvcf with gatk GenotypeGVCFs
gatk GenotypeGVCFs --java-options {params.mem} {knvars} -R {input.ref} -V {input.gvcf} -O {output.raw_vcf}
## Custom R script"

``` {bash}


#add agbiome conda channel 
cmatt5@crick:~$ srun -J osu -t 6:00:00 --mem=25gb -c 1 --pty bash
(base) cmatt5@c2-3:~$ conda config --add channels agbiome
(base) cmatt5@c2-3:~$ conda activate osu
(osu) cmatt5@c2-3:~$ conda install -c agbiome bbtools

#need bbmap 
wget https://sourceforge.net/projects/bbmap/files/latest/download
mv download ./BBMap_38.90.tar.gz
tar -xvzf BBMap_38.90.tar.gz


#instal bwa
git clone https://github.com/lh3/bwa.git
cd bwa; make
./bwa mem ref.fa read-se.fq.gz | gzip -3 > aln-se.sam.gz
./bwa mem ref.fa read1.fq read2.fq | gzip -3 > aln-pe.sam.gzgcc -c -g -Wall -Wno-unused-function -O2 -DHAVE_PTHREAD -DUSE_MALLOC_WRAPPERS  utils.c -o utils.o

#samtools
 conda install samtools
 # All requested packages already installed.
 
#install primerclip
conda install -c bioconda primerclip

#install gatk
#get gatk package
#in osu/data dir:
wget https://github.com/broadinstitute/gatk/releases/download/4.2.0.0/gatk-4.2.0.0.zip
unzip gatk-4.2.0.0.zip
#add to path (idk what this means but the gatk website said to do it)
export PATH="./gatk-4.2.0.0/:$PATH"
cd gatk-4.2.0.0
conda env create -n gatk -f gatkcondaenv.yml
source activate gatk
#bioconda conda installation IS A NO GO


#download wuhan hu 1 reference .fa from ncbi

#copy example files fromm minimap workflo dir

#start workflow on example data - 1st step trim adapters w bbduk
#idk what params.mem is ....? taking out for now
#doing 4 threads because ..... ?
#make sure no spaces after = signs 
#doesnt seem to like * character, hard coded file names for now
#bbmap folder is in ~
 bbduk.sh ktrim=r k=23 mink=11 hdist=1 qtrim=r1 trimq=15 minlength=30 maxns=0 t=4 in1=GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R1_001.fastq.gz in2=GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R2_001.fastq.gz out1=GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R1_001.bbduk.fastq.gz out2=GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14_R2_001.bbduk.fastq.gz ref=../../../bbmap/resources/adapters.fa
 
 #need to make bwa reference genome index with 
 #bwa index [-p prefix] [-a algoType] <in.db.fasta>
 bwa index ../../sarscov2WuhanHu1.fasta #makes a bunch of files in the parent dir
 
 ## Run BWA mem - keep 4 threads ??? 
# line from brett: bwa mem -t 4 -M -R '{params.rg}' {input.fa} {input.fq} > {output.sam}
 # idk what params.rg is, think it has to do with read group name and output sequence ID's .... lets see what happens if I do a test line
 # I think the input.fa is the reference, and I can put 2 paired read files as file1.fq file 2.fq back to back
bwa mem -t 4 -M -R '@RG\tID:NULL\tSM:TEST\tLB:NULL\tPL:Illumina' ../../sarscov2WuhanHu1.fasta *R1_001.bbduk.fastq.gz *R2_001.bbduk.fastq.gz > GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sam


#samtools sort .sam
samtools sort -n GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sam -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.sam

#primerclip
#masterfiles available here: https://swiftbiosci.com/accel-amplicon-data-and-bioinformatics-tools-downloads/
#not sure which sarscov2 file ( standard vs addtnl genome coverage) will stick w standard for now
wget https://swiftbiosci.com/wp-content/uploads/2020/09/sarscov2_v1_masterfile.txt.zip
unzip sarscov2_v1_masterfile.txt.zip
#primerclip masterfile.txt alignmentfile.sam outputfilename.sam
primerclip sarscov2_v1_masterfile.txt GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.sam GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.primerclipped.sam

#Convert sam to bam
samtools view -b GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.primerclipped.sam -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.bam

#Sort reads
samtools sort GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.bam -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam

#Index reads
samtools index GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam

#Get depth from Bam files
samtools depth -a GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam | awk '$3 < 5' | cut -f 1,2 > output.depth
#output.depth is a .txt


#call variants!
gatk HaplotypeCaller --java-options {params.mem} -R {input.ref} -ERC GVCF -stand-call-conf 20 --dont-use-soft-clipped-bases -mbq 20 --max-reads-per-alignment-start 0 --linked-de-bruijn-graph --recover-all-dangling-branches --sample-ploidy {params.ploidy} --input {input.dedup} --output {output.gvcf}
#idk what params.mem is, skipping for now
#--java-options appears to be memory allocation ..? using "-Xmx4g" bc thats in the example on the help website (below)
#input.dedup .... https://gatk.broadinstitute.org/hc/en-us/articles/360037225632-HaplotypeCaller claims that duplicate reads are automatically filtered out. skipping for now?

(gatk) cmatt5@c2-3:~/SARS-COV2/osu/data/gatk-4.2.0.0$ cd ..
#make reference genome dictionary
(gatk) cmatt5@c2-3:~/SARS-COV2/osu/data$ gatk-4.2.0.0/gatk CreateSequenceDictionary -R ../../sarscov2WuhanHu1.fasta
#make reference genome index
samtools faidx sarscov2WuhanHu1.fasta

#add fake read group ID bc it apparently is required ...
(gatk) cmatt5@c2-3:~/SARS-COV2/osu/data$ samtools addreplacerg -r 'ID:C01234' -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.addRG.bam GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam
(gatk) cmatt5@c2-3:~/SARS-COV2/osu/data$ gatk-4.2.0.0/gatk --java-options "-Xmx4g" HaplotypeCaller -R ./sarscov2WuhanHu1.fasta -ERC GVCF -stand-call-conf 20 --dont-use-soft-clipped-bases -mbq 20 --max-reads-per-alignment-start 0 --linked-de-bruijn-graph --recover-all-dangling-branches --sample-ploidy 1 --sample-name 'TEST' --read-filter 'NotDuplicateReadFilter' --input GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam --output GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.gvcf

## Combine gvcfs - skip for now, only have one file
gatk CombineGVCFs --java-options {params.mem} -R ./sarscov2WuhanHu1.fasta {lgvcfs} -O {output.gvcf}

## Genotype merged gvcf with gatk GenotypeGVCFs
gatk GenotypeGVCFs --java-options {params.mem} {knvars} -R {input.ref} -V {input.gvcf} -O {output.raw_vcf}
#not sure what knvars is, but i think its indicating that we might be combining multiple vcfs
gatk-4.2.0.0/gatk GenotypeGVCFs --java-options "-Xmx4g"  -R ./sarscov2WuhanHu1.fasta -V GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.gvcf -O GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.vcf




```



## test ivar pipeline on same file set ##
```{bash}
#ivar starts with primer trimming of existing sorted BAM file
#need primer BED file, only have masterfile.txt. got .bed from Ryan Davis

#will need reference GFF file (from ncbi)
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar$ wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/858/895/GCF_009858895.2_ASM985889v3/GCF_009858895.2_ASM985889v3_genomic.gff.gz
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar$ gunzip *.gz

Lets try ivar on BAM from Titus minimap wf (minimap based)and BAM (bwa mem based) from OSU workflow
mkdir minimap
mkdir osu
#copy sorted bam file and index files (.bai) to respective ivar directory
#rename minimap bam to end with '.bam''
mv GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.covid19.bam.sorted GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.covid19.sorted.bam

(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/minimap$ samtools index GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.covid19.sorted.bam

#next, ivar trim
#Usage: ivar trim -i <input.bam> -b <primers.bed> -p <prefix> [-m <min-length>] [-q <min-quality>] [-s <sliding-window-width>]
#Input Options    Description
#           -i    (Required) Sorted bam file, with aligned reads, to trim primers and quality
#           -b    (Required) BED file with primer sequences and positions
#           -m    Minimum length of read to retain after trimming (Default: 30)
#           -q    Minimum quality threshold for sliding window to pass (Default: 20)
#           -s    Width of sliding window (Default: 4)
#           -e    Include reads with no primers. By default, reads with no primers are excluded
#Output Options   Description
#           -p    (Required) Prefix for the output BAM file

(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/minimap$ ivar trim -i GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.abundtrim.covid19.sorted.bam -b ../NC_045512.2.v2.primers.bed -p 'GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed'

#need to sort trimmed files?
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/minimap$ samtools sort -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.sorted.bam GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.bam

#call variants with  pileup piped into ivar variants:
#samtools mpileup -aa -A -d 0 -B -Q 0 --reference [<reference-fasta] <input.bam> | ivar variants -p <prefix> [-q <min-quality>] [-t <min-frequency-threshold>] [-m <minimum depth>] [-r <reference-fasta>] [-g GFF file]
#will not specify depth or quality yet, just want to compare bam starting points
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/minimap$ samtools mpileup -aa -A -d 0 -B -Q 0 --reference ../../sarscov2WuhanHu1.fasta GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.sorted.bam | ivar variants -p GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.variants -r ../../sarscov2WuhanHu1.fasta -g ../GCF_009858895.2_ASM985889v3_genomic.gff

#repeat in ivar/osu
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/osu$ samtools index GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/osu$ ivar trim -i GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.sorted.bam -b ../NC_045512.2.v2.primers.bed -p 'GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed'
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/osu$ samtools sort -o GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.sorted.bam GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.bam
(ivar) cmatt5@c2-3:~/SARS-COV2/ivar/minimap$ samtools mpileup -aa -A -d 0 -B -Q 0 --reference ../../sarscov2WuhanHu1.fasta GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.ivartrimmed.sorted.bam | ivar variants -p 'osu.GSR_SWIFT_2021_04_06_O20_001_020821_C1E1_S14.variants' -r ../../sarscov2WuhanHu1.fasta -g ../GCF_009858895.2_ASM985889v3_genomic.gff


#resulting file very short .... weird
```




### testing artic####

```{bash}
Github: https://github.com/artic-network/fieldbioinformatics
ARTIC 'SOP' : https://artic.network/ncov-2019/ncov2019-bioinformatics-sop.html

git clone https://github.com/artic-network/fieldbioinformatics
cd fieldbioinformatics 
conda env create -f environment.yml
















